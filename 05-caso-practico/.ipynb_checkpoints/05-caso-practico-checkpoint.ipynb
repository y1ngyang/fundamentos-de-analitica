{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso Práctico\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/IPython-for-data-science/blob/master/05-caso-practico/05-caso-practico.ipynb) para acceder a la última versión online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/IPython-for-data-science/blob/master/05-caso-practico/05-caso-practico.ipynb) para ver la última versión online en `nbviewer`. \n",
    "\n",
    "---\n",
    "[Licencia](https://github.com/jdvelasq/IPython-for-data-science/blob/master/LICENCIA.txt)  \n",
    "[Readme](https://github.com/jdvelasq/IPython-for-data-science/blob/master/readme.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este directorio contiene la información de cuatro (4) estaciones automáticas de medición de viento. Se desear realizar un proceso de transformación de los datos con el fin de producir la información requerida para construir un atlas eólico de la región. A continuación se presentan los requerimientos solicitados y su respectiva solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimiento 1.--** Generar una tabla unificada que contenga las siguientes columnas:\n",
    "\n",
    "* Nombre de la estación.\n",
    "* Fecha en el formato YYYY-MM-DD.\n",
    "* Año.\n",
    "* Mes.\n",
    "* Dia.\n",
    "* HHMMSS.\n",
    "* Hora (HH).\n",
    "* Minuto (MM).\n",
    "* Dirección.\n",
    "* Velocidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## archivo de salida\n",
    "##\n",
    "file_out = open('tabla1.csv', 'w')\n",
    "  \n",
    "## se agrega el encabezamiento\n",
    "file_out.write(\"ESTACION,FECHA,ANO,MES,DIA,HHMMSS,HORA,MIN,DIR,VEL\\n\")\n",
    "    \n",
    "##\n",
    "## se recorren todos los archivos *csv en el directorio \n",
    "##\n",
    "for filename in glob.glob(\"Es*.csv\"):\n",
    "    \n",
    "    ## abre el archivo para lectura\n",
    "    file_in = open(filename, 'r')\n",
    "    \n",
    "    ## se ignora la primera linea de encabezados\n",
    "    isfirstline = True\n",
    "    \n",
    "    ## se leen una a una las lineas del archivo *csv\n",
    "    for line in file_in:\n",
    "        \n",
    "        ## se ignora la primera linea de encabezados\n",
    "        if isfirstline is True:\n",
    "            isfirstline = False\n",
    "            continue\n",
    "        \n",
    "        ##\n",
    "        ## se agrega el nombre del archivo\n",
    "        ##\n",
    "        line = filename[:-4] + ';' + line\n",
    "        \n",
    "        ##\n",
    "        ## Se cambian las ',' por '.'\n",
    "        ##\n",
    "        line = line.replace(',', '.')\n",
    "        \n",
    "        ##\n",
    "        ## Se cambian los ';' por ','\n",
    "        ##\n",
    "        line = line.replace(';', ',')\n",
    "        \n",
    "        ##\n",
    "        ## Se extrae de HH:MM:SS las HH y los MM\n",
    "        ##\n",
    "        groups = re.search(',([0-9]+):([0-9][0-9]):([0-9][0-9])', line)\n",
    "        if groups:\n",
    "            org_text = groups.group(0)\n",
    "            new_text = org_text + ',' + groups[1] + ',' + groups[2]\n",
    "            line = line.replace(org_text, new_text)\n",
    "        \n",
    "        ##\n",
    "        ## Se agrega el 0 al digito del dia\n",
    "        ##\n",
    "        groups = re.search(',([0-9])/', line)\n",
    "        if groups:\n",
    "            org_text = groups.group(0)\n",
    "            new_text = '0' + groups.group(1) + '/'\n",
    "            line = line.replace(org_text, new_text)\n",
    "\n",
    "\n",
    "        ## Se cambia el formato DD/MM/YY a YYYY-MM-DD\n",
    "        ## y agrega las columnas año, mes, dia\n",
    "        groups = re.search('([0-9][0-9])\\/([0-9][0-9])\\/([0-9][0-9])', line)  \n",
    "        org_text = groups.group(0)\n",
    "        new_text = '20' + groups.group(3) + '-' + groups.group(2) + '-' + groups.group(1) \n",
    "        new_text +=  ',20' + groups.group(3) + ',' + groups.group(2) + ',' + groups.group(1) \n",
    "        \n",
    "        # print(lineaorg_text, '\\n', new_text, sep = '')\n",
    "        line = line.replace(org_text, new_text)\n",
    "        \n",
    "        ##\n",
    "        ## se escribe la linea modificada al archivo de salida\n",
    "        ##\n",
    "        file_out.write(line)\n",
    "    \n",
    "    file_in.close()\n",
    "\n",
    "file_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTACION,FECHA,ANO,MES,DIA,HHMMSS,HORA,MIN,DIR,VEL\r\n",
      "Estacion1,2005-04-16,2005,04,16,11:10:00,11,10,135,6.3\r\n",
      "Estacion1,2005-04-16,2005,04,16,11:20:00,11,20,135,5.1\r\n",
      "Estacion1,2005-04-16,2005,04,16,11:30:00,11,30,135,6.3\r\n",
      "Estacion1,2005-04-16,2005,04,16,11:40:00,11,40,113,6.1\r\n",
      "Estacion1,2005-04-16,2005,04,16,11:50:00,11,50,135,4.1\r\n",
      "Estacion1,2005-04-16,2005,04,16,12:00:00,12,00,135,5.5\r\n",
      "Estacion1,2005-04-16,2005,04,16,12:10:00,12,10,135,5.4\r\n",
      "Estacion1,2005-04-16,2005,04,16,12:20:00,12,20,135,5.5\r\n",
      "Estacion1,2005-04-16,2005,04,16,12:30:00,12,30,90,4.6\r\n"
     ]
    }
   ],
   "source": [
    "!head tabla1.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimiento 2.--** Generar una tabla unificada que contenga las siguientes columnas:\n",
    "\n",
    "* Nombre de la estación.\n",
    "* Año.\n",
    "* Mes.\n",
    "* Dia.\n",
    "* Hora.\n",
    "* Velocidad media del viento para la correspodiente hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = open('tabla1.csv', 'r')\n",
    "isfirstline = True\n",
    "dicvel = {}\n",
    "for line in file_in:\n",
    "\n",
    "    ## se ignora la primera linea de encabezados\n",
    "    if isfirstline is True:\n",
    "        isfirstline = False\n",
    "        continue\n",
    "\n",
    "    line = line.split(',')\n",
    "    clave = line[0] + '-' + line[1] + '-' + line[6]\n",
    "    \n",
    "    if clave in dicvel.keys():\n",
    "        dicvel[clave] = dicvel[clave] + [float(line[-1])] \n",
    "    else:\n",
    "        dicvel[clave] = [float(line[-1])] \n",
    "    \n",
    "file_in.close()\n",
    "\n",
    "dicvel_prom = dicvel.copy()\n",
    "\n",
    "\n",
    "for clave in dicvel:\n",
    "    dicvel_prom[clave] = round(sum(dicvel[clave]) / len(dicvel[clave]), 2)\n",
    "    \n",
    "file_out = open('tabla2.csv', 'w')\n",
    "\n",
    "## se agrega el encabezamiento\n",
    "file_out.write(\"ESTACION,ANO,MES,DIA,HORA,VEL\\n\")\n",
    "\n",
    "for clave in dicvel_prom:\n",
    "    text =  clave + '-' + str(dicvel_prom[clave])\n",
    "    text = text.replace('-', ',')\n",
    "    file_out.write(text + '\\n')\n",
    "    \n",
    "file_out.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Estacion1-2005-04-16-11': [6.3, 5.1, 6.3, 6.1, 4.1],\n",
       " 'Estacion1-2005-04-16-12': [5.5, 5.4, 5.5, 4.6, 6.7, 5.0],\n",
       " 'Estacion1-2005-04-16-13': [5.5, 5.8, 5.3, 4.2, 3.8, 4.6],\n",
       " 'Estacion1-2005-04-16-14': [4.5, 3.7, 2.8, 3.4, 4.6, 3.0],\n",
       " 'Estacion1-2005-04-16-15': [2.5, 3.1, 2.6, 4.1, 4.2, 4.3],\n",
       " 'Estacion1-2005-04-16-16': [3.3, 4.3, 4.3, 3.9, 2.3, 4.1],\n",
       " 'Estacion1-2005-04-16-17': [4.6, 5.6, 5.1, 6.1, 4.3, 3.3],\n",
       " 'Estacion1-2005-04-16-18': [4.1, 4.3, 4.1, 4.5, 5.4, 6.2],\n",
       " 'Estacion1-2005-04-16-19': [4.3, 4.0, 2.5, 4.8]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicvel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimiento 3.--** Generar una tabla que contenga las siguientes columnas:\n",
    "\n",
    "* Estación.\n",
    "* Año.\n",
    "* Mes.\n",
    "* Velocidad media del viento para ese mes y ese año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## para resolver en clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimiento 4.--** Generar una tabla que contenga las siguientes columnas:\n",
    "\n",
    "* Estación.\n",
    "* Año.\n",
    "* Velocidad media para dicho año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## para resolver en clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimiento 5.--** Generar una tabla que contenga las siguientes columnas:\n",
    "\n",
    "* Estación.\n",
    "* Mes.\n",
    "* Velocidad media para ese mes calculada sobre todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## para resolver en clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimiento 6.--** Generar una tabla que contenga las siguientes columnas:\n",
    "\n",
    "* Estación.\n",
    "* Hora.\n",
    "* Velocidad media para ese hora calculada sobre todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## para resolver en clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requerimiento 7.--** Generar una tabla que contenga las siguientes columnas:\n",
    "\n",
    "* Estación.\n",
    "* Mes (MM).\n",
    "* Hora (HH).\n",
    "* Velocidad media para ese mes y esa hora calculada sobre todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## para resolver en clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso Práctico\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/IPython-for-data-science/blob/master/05-caso-practico/05-caso-practico.ipynb) para acceder a la última versión online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/IPython-for-data-science/blob/master/05-caso-practico/05-caso-practico.ipynb) para ver la última versión online en `nbviewer`. \n",
    "\n",
    "---\n",
    "[Licencia](https://github.com/jdvelasq/IPython-for-data-science/blob/master/LICENCIA.txt)  \n",
    "[Readme](https://github.com/jdvelasq/IPython-for-data-science/blob/master/readme.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
